{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":616904,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":463752,"modelId":479547}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install adversarial-robustness-toolbox","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n\nimport numpy as np\nfrom art.attacks.evasion import ProjectedGradientDescent\nfrom art.estimators.classification import PyTorchClassifier\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE = 128\nEPOCHS = 10\nLR = 1e-3\nLAMBDA_CLS = 0.5\n\nprint(\"Using device:\", DEVICE)\n\nCIFAR_MEAN = torch.tensor([0.4914, 0.4822, 0.4465]).view(1,3,1,1).to(DEVICE)\nCIFAR_STD  = torch.tensor([0.2023, 0.1994, 0.2010]).view(1,3,1,1).to(DEVICE)\n\ndef normalize_cifar10(x):\n    return (x - CIFAR_MEAN) / CIFAR_STD\n\ntransform = transforms.Compose([\n    transforms.ToTensor()\n])\n\ntrain_dataset = torchvision.datasets.CIFAR10(\n    root=\"./data\", train=True, download=True, transform=transform\n)\n\ntrain_loader = DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2\n)\n\ndef make_resnet18_cifar10():\n    model = torchvision.models.resnet18(weights=None)\n    model.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n    model.maxpool = nn.Identity()\n    model.fc = nn.Linear(model.fc.in_features, 10)\n    return model\n\nclassifier = make_resnet18_cifar10().to(DEVICE)\nclassifier.load_state_dict(\n    torch.load(\"/kaggle/input/baseline-model/pytorch/default/1/temp_baseline_resnet_cifar.pth\", map_location=DEVICE)\n)\nclassifier.eval()\n\ncriterion = nn.CrossEntropyLoss()\n\nart_classifier = PyTorchClassifier(\n    model=classifier,\n    loss=criterion,\n    optimizer=None,\n    input_shape=(3,32,32),\n    nb_classes=10,\n    device_type=DEVICE.type\n)\n\npgd_attack = ProjectedGradientDescent(\n    estimator=art_classifier,\n    eps=8/255,\n    eps_step=2/255,\n    max_iter=10,\n    batch_size=BATCH_SIZE\n)\n\nclass PurifierUNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.enc1 = nn.Sequential(\n            nn.Conv2d(3, 64, 3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, 3, padding=1),\n            nn.ReLU()\n        )\n        self.pool1 = nn.MaxPool2d(2)\n\n        self.enc2 = nn.Sequential(\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, 3, padding=1),\n            nn.ReLU()\n        )\n        self.pool2 = nn.MaxPool2d(2)\n\n        self.bottleneck = nn.Sequential(\n            nn.Conv2d(128, 256, 3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, 3, padding=1),\n            nn.ReLU()\n        )\n\n        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n        self.dec2 = nn.Sequential(\n            nn.Conv2d(256, 128, 3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, 3, padding=1),\n            nn.ReLU()\n        )\n\n        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n        self.dec1 = nn.Sequential(\n            nn.Conv2d(128, 64, 3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 3, 3, padding=1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        p1 = self.pool1(e1)\n\n        e2 = self.enc2(p1)\n        p2 = self.pool2(e2)\n\n        b = self.bottleneck(p2)\n\n        d2 = self.up2(b)\n        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n\n        d1 = self.up1(d2)\n        out = self.dec1(torch.cat([d1, e1], dim=1))\n        return out\n\npurifier = PurifierUNet().to(DEVICE)\n\noptimizer = optim.Adam(purifier.parameters(), lr=LR)\nrecon_loss = nn.MSELoss()\ncls_loss = nn.CrossEntropyLoss()\n\nfor epoch in range(EPOCHS):\n    purifier.train()\n    running_loss = 0.0\n\n    for x_clean, y in train_loader:\n        x_clean = x_clean.to(DEVICE)\n        y = y.to(DEVICE)\n\n        x_adv = pgd_attack.generate(x_clean.detach().cpu().numpy())\n        x_adv = torch.tensor(x_adv).to(DEVICE)\n\n        x_pur = purifier(x_adv)\n\n        loss_recon = recon_loss(x_pur, x_clean)\n        logits = classifier(normalize_cifar10(x_pur))\n        loss_cls = cls_loss(logits, y)\n\n        loss = loss_recon + LAMBDA_CLS * loss_cls\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"[Epoch {epoch+1}/{EPOCHS}] Loss: {running_loss/len(train_loader):.4f}\")\n\ntorch.save(purifier.state_dict(), \"purifier_unet_cifar10.pth\")\nprint(\"Purifier model saved.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}