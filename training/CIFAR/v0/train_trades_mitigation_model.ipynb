{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# trades_cifar10_fixed.py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n\nfrom torchvision.models import resnet18\nimport numpy as np\nimport random\nfrom tqdm import tqdm\n\n# --------------------------\n# 1. Reproducibility\n# --------------------------\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# --------------------------\n# 2. Hyperparameters\n# --------------------------\nbatch_size = 128\nlearning_rate = 0.01  # smaller for stability\nnum_epochs = 80\nepsilon = 8/255  # L_inf perturbation\nalpha = 2/255    # PGD step size\nnum_steps = 10   # PGD steps\nbeta = 6.0       # TRADES trade-off\n\n# --------------------------\n# 3. CIFAR-10 Data\n# --------------------------\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n])\n\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n# --------------------------\n# 4. Model\n# --------------------------\nmodel = resnet18(num_classes=10).to(device)\n\n# --------------------------\n# 5. TRADES Loss Function\n# --------------------------\ndef trades_loss(model, x_natural, y):\n    model.train()\n    batch_size = len(x_natural)\n\n    # Initialize adversarial example\n    x_adv = x_natural.detach() + 0.001 * torch.randn_like(x_natural)\n    for _ in range(num_steps):\n        x_adv.requires_grad_()\n        logits_adv = model(x_adv)\n        logits_nat = model(x_natural)\n        loss_kl = F.kl_div(F.log_softmax(logits_adv, dim=1),\n                           F.softmax(logits_nat, dim=1),\n                           reduction='batchmean')\n        grad = torch.autograd.grad(loss_kl, [x_adv])[0]\n        x_adv = x_adv + alpha * torch.sign(grad)\n        x_adv = torch.min(torch.max(x_adv, x_natural - epsilon), x_natural + epsilon)\n        x_adv = torch.clamp(x_adv, 0.0, 1.0).detach()\n\n    # Compute TRADES loss\n    logits = model(x_natural)\n    logits_adv = model(x_adv)\n    loss_ce = F.cross_entropy(logits, y)\n    loss_kl = F.kl_div(F.log_softmax(logits_adv, dim=1),\n                       F.softmax(logits, dim=1),\n                       reduction='batchmean')\n    loss = loss_ce + beta * loss_kl\n    return loss\n\n# --------------------------\n# 6. Optimizer & Scheduler\n# --------------------------\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\nscheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 25], gamma=0.1)\n\n# --------------------------\n# 7. Evaluation Function\n# --------------------------\ndef evaluate(model, loader, adversarial=False):\n    model.eval()\n    correct = 0\n    total = 0\n    for images, labels in loader:\n        images, labels = images.to(device), labels.to(device)\n        if adversarial:\n            x_adv = images.detach() + 0.001 * torch.randn_like(images)\n            for _ in range(num_steps):\n                x_adv.requires_grad_()\n                logits = model(x_adv)\n                loss = F.cross_entropy(logits, labels)\n                grad = torch.autograd.grad(loss, [x_adv])[0]\n                x_adv = x_adv + alpha * torch.sign(grad)\n                x_adv = torch.min(torch.max(x_adv, images - epsilon), images + epsilon)\n                x_adv = torch.clamp(x_adv, 0.0, 1.0).detach()\n            outputs = model(x_adv)\n        else:\n            outputs = model(images)\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n    acc = 100.0 * correct / total\n    return acc\n\n# --------------------------\n# 8. Training Loop\n# --------------------------\nprint(\"Starting TRADES training...\")\nfor epoch in range(1, num_epochs+1):\n    model.train()\n    running_loss = 0.0\n    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs}\"):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        loss = trades_loss(model, images, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n    scheduler.step()\n    avg_loss = running_loss / len(train_loader.dataset)\n    clean_acc = evaluate(model, test_loader, adversarial=False)\n    adv_acc = evaluate(model, test_loader, adversarial=True)\n    print(f\"Epoch [{epoch}/{num_epochs}] | Loss: {avg_loss:.4f} | Clean Acc: {clean_acc:.2f}% | Adv Acc: {adv_acc:.2f}%\")\n\n# --------------------------\n# 9. Save Model\n# --------------------------\ntorch.save(model.state_dict(), \"trades_resnet18_cifar10_fixed.pth\")\nprint(\"Training completed and model saved!\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-21T13:08:27.017736Z","iopub.execute_input":"2025-10-21T13:08:27.018024Z","iopub.status.idle":"2025-10-21T15:38:42.749856Z","shell.execute_reply.started":"2025-10-21T13:08:27.017987Z","shell.execute_reply":"2025-10-21T15:38:42.748587Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nStarting TRADES training...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/80: 100%|██████████| 391/391 [02:20<00:00,  2.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/80] | Loss: 2.2856 | Clean Acc: 34.00% | Adv Acc: 19.72%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/80] | Loss: 2.0289 | Clean Acc: 36.84% | Adv Acc: 18.69%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/80] | Loss: 1.9746 | Clean Acc: 39.66% | Adv Acc: 20.85%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/80] | Loss: 1.9338 | Clean Acc: 40.86% | Adv Acc: 20.01%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/80] | Loss: 1.9055 | Clean Acc: 44.12% | Adv Acc: 23.62%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/80] | Loss: 1.8855 | Clean Acc: 45.87% | Adv Acc: 24.65%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/80] | Loss: 1.8555 | Clean Acc: 45.23% | Adv Acc: 24.76%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/80] | Loss: 1.8447 | Clean Acc: 46.61% | Adv Acc: 24.17%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/80] | Loss: 1.8334 | Clean Acc: 46.54% | Adv Acc: 23.72%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/80] | Loss: 1.8143 | Clean Acc: 46.15% | Adv Acc: 23.39%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [11/80] | Loss: 1.8093 | Clean Acc: 46.60% | Adv Acc: 24.78%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [12/80] | Loss: 1.7909 | Clean Acc: 50.05% | Adv Acc: 25.71%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [13/80] | Loss: 1.7823 | Clean Acc: 47.64% | Adv Acc: 27.46%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [14/80] | Loss: 1.7694 | Clean Acc: 50.97% | Adv Acc: 25.90%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [15/80] | Loss: 1.7609 | Clean Acc: 51.21% | Adv Acc: 27.57%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [16/80] | Loss: 1.7217 | Clean Acc: 53.09% | Adv Acc: 28.33%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [17/80] | Loss: 1.7149 | Clean Acc: 53.83% | Adv Acc: 28.07%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [18/80] | Loss: 1.7111 | Clean Acc: 52.25% | Adv Acc: 28.23%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [19/80] | Loss: 1.7095 | Clean Acc: 53.79% | Adv Acc: 27.40%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [20/80] | Loss: 1.7079 | Clean Acc: 54.52% | Adv Acc: 27.69%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [21/80] | Loss: 1.7054 | Clean Acc: 52.73% | Adv Acc: 27.20%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [22/80] | Loss: 1.7044 | Clean Acc: 54.08% | Adv Acc: 28.24%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [23/80] | Loss: 1.7016 | Clean Acc: 54.32% | Adv Acc: 28.84%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [24/80] | Loss: 1.6990 | Clean Acc: 52.65% | Adv Acc: 26.95%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [25/80] | Loss: 1.6984 | Clean Acc: 53.87% | Adv Acc: 27.99%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [26/80] | Loss: 1.6964 | Clean Acc: 53.83% | Adv Acc: 27.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [27/80] | Loss: 1.6919 | Clean Acc: 53.09% | Adv Acc: 28.43%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [28/80] | Loss: 1.6931 | Clean Acc: 54.13% | Adv Acc: 28.29%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [29/80] | Loss: 1.6951 | Clean Acc: 53.18% | Adv Acc: 27.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [30/80] | Loss: 1.6906 | Clean Acc: 54.20% | Adv Acc: 28.60%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [31/80] | Loss: 1.6916 | Clean Acc: 53.99% | Adv Acc: 28.00%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [32/80] | Loss: 1.6931 | Clean Acc: 54.23% | Adv Acc: 28.31%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [33/80] | Loss: 1.6934 | Clean Acc: 53.81% | Adv Acc: 27.27%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/80: 100%|██████████| 391/391 [02:19<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [34/80] | Loss: 1.6913 | Clean Acc: 54.78% | Adv Acc: 28.76%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [35/80] | Loss: 1.6920 | Clean Acc: 53.86% | Adv Acc: 28.39%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [36/80] | Loss: 1.6909 | Clean Acc: 53.51% | Adv Acc: 28.09%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [37/80] | Loss: 1.6904 | Clean Acc: 54.27% | Adv Acc: 27.75%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [38/80] | Loss: 1.6923 | Clean Acc: 53.87% | Adv Acc: 28.13%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [39/80] | Loss: 1.6921 | Clean Acc: 54.90% | Adv Acc: 28.02%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [40/80] | Loss: 1.6920 | Clean Acc: 53.93% | Adv Acc: 28.28%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [41/80] | Loss: 1.6914 | Clean Acc: 54.64% | Adv Acc: 28.78%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [42/80] | Loss: 1.6919 | Clean Acc: 53.90% | Adv Acc: 28.75%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [43/80] | Loss: 1.6901 | Clean Acc: 55.32% | Adv Acc: 28.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 44/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [44/80] | Loss: 1.6891 | Clean Acc: 53.62% | Adv Acc: 28.51%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 45/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [45/80] | Loss: 1.6896 | Clean Acc: 55.02% | Adv Acc: 28.56%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [46/80] | Loss: 1.6903 | Clean Acc: 54.49% | Adv Acc: 28.33%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 47/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [47/80] | Loss: 1.6897 | Clean Acc: 54.04% | Adv Acc: 28.84%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 48/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [48/80] | Loss: 1.6892 | Clean Acc: 53.83% | Adv Acc: 27.49%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 49/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [49/80] | Loss: 1.6912 | Clean Acc: 54.18% | Adv Acc: 28.30%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 50/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [50/80] | Loss: 1.6900 | Clean Acc: 53.99% | Adv Acc: 28.36%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 51/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [51/80] | Loss: 1.6890 | Clean Acc: 54.83% | Adv Acc: 28.45%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 52/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [52/80] | Loss: 1.6889 | Clean Acc: 53.96% | Adv Acc: 27.98%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 53/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [53/80] | Loss: 1.6891 | Clean Acc: 53.78% | Adv Acc: 28.54%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 54/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [54/80] | Loss: 1.6882 | Clean Acc: 55.25% | Adv Acc: 28.94%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 55/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [55/80] | Loss: 1.6895 | Clean Acc: 52.84% | Adv Acc: 28.01%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 56/80: 100%|██████████| 391/391 [02:19<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [56/80] | Loss: 1.6887 | Clean Acc: 54.35% | Adv Acc: 28.63%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 57/80:  53%|█████▎    | 207/391 [01:14<01:05,  2.79it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/2583623017.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"torch.save(model.state_dict(), \"trades_resnet18_cifar10_fixed.pth\")\nprint(\"Training completed and model saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T15:38:46.476944Z","iopub.execute_input":"2025-10-21T15:38:46.477574Z","iopub.status.idle":"2025-10-21T15:38:46.617690Z","shell.execute_reply.started":"2025-10-21T15:38:46.477545Z","shell.execute_reply":"2025-10-21T15:38:46.616906Z"}},"outputs":[{"name":"stdout","text":"Training completed and model saved!\n","output_type":"stream"}],"execution_count":2}]}