{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af48cb09-cb4e-4709-a805-993b80725ac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T15:01:43.735335Z",
     "iopub.status.busy": "2025-12-18T15:01:43.734607Z",
     "iopub.status.idle": "2025-12-18T15:01:47.989273Z",
     "shell.execute_reply": "2025-12-18T15:01:47.988348Z",
     "shell.execute_reply.started": "2025-12-18T15:01:43.735301Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting adversarial-robustness-toolbox\n",
      "  Downloading adversarial_robustness_toolbox-1.20.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.2.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (75.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (2.4.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (3.6.0)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.18.0->adversarial-robustness-toolbox) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (2024.2.0)\n",
      "Downloading adversarial_robustness_toolbox-1.20.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: adversarial-robustness-toolbox\n",
      "Successfully installed adversarial-robustness-toolbox-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "402a195c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T15:05:26.218082Z",
     "iopub.status.busy": "2025-12-18T15:05:26.217821Z",
     "iopub.status.idle": "2025-12-18T15:05:26.222524Z",
     "shell.execute_reply": "2025-12-18T15:05:26.221719Z",
     "shell.execute_reply.started": "2025-12-18T15:05:26.218065Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff3a2c-dcfb-43f3-b4ba-e41cc1cdaba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T15:05:28.822556Z",
     "iopub.status.busy": "2025-12-18T15:05:28.822294Z",
     "iopub.status.idle": "2025-12-18T15:05:28.841388Z",
     "shell.execute_reply": "2025-12-18T15:05:28.840819Z",
     "shell.execute_reply.started": "2025-12-18T15:05:28.822538Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for dataset...\n",
      "Found Input Path: /kaggle/input/imagenet100/train.X1\n"
     ]
    }
   ],
   "source": [
    "print(\"Searching for dataset...\")\n",
    "found_path = None\n",
    "for root, dirs, files in os.walk('/kaggle/input'):\n",
    "    if 'n01440764' in dirs: \n",
    "        found_path = root\n",
    "        print(f\"Found Input Path: {found_path}\")\n",
    "        break\n",
    "\n",
    "if not found_path:\n",
    "    for root, dirs, files in os.walk('/kaggle/input'):\n",
    "        if 'train' in dirs:\n",
    "            found_path = os.path.join(root, 'train')\n",
    "            print(f\"Using fallback path: {found_path}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3b51ec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T15:05:31.390089Z",
     "iopub.status.busy": "2025-12-18T15:05:31.389815Z",
     "iopub.status.idle": "2025-12-18T15:05:31.393827Z",
     "shell.execute_reply": "2025-12-18T15:05:31.393193Z",
     "shell.execute_reply.started": "2025-12-18T15:05:31.390071Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "INPUT_ROOT = found_path\n",
    "OUTPUT_ROOT = '/kaggle/working/imagenet100_adversarial/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fadab83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T15:05:32.986711Z",
     "iopub.status.busy": "2025-12-18T15:05:32.986414Z",
     "iopub.status.idle": "2025-12-18T15:05:32.992264Z",
     "shell.execute_reply": "2025-12-18T15:05:32.991518Z",
     "shell.execute_reply.started": "2025-12-18T15:05:32.986665Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardware: cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPSILON = 8/255\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Hardware: {device}\")\n",
    "\n",
    "if os.path.exists(OUTPUT_ROOT):\n",
    "    shutil.rmtree(OUTPUT_ROOT) \n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6431c9d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T15:05:35.751624Z",
     "iopub.status.busy": "2025-12-18T15:05:35.751153Z",
     "iopub.status.idle": "2025-12-18T15:05:36.398786Z",
     "shell.execute_reply": "2025-12-18T15:05:36.398033Z",
     "shell.execute_reply.started": "2025-12-18T15:05:35.751601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 classes. Creating target folders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 236MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [d for d in os.listdir(INPUT_ROOT) if os.path.isdir(os.path.join(INPUT_ROOT, d))]\n",
    "classes.sort()\n",
    "print(f\"Found {len(classes)} classes. Creating target folders...\")\n",
    "\n",
    "for cls in classes:\n",
    "    os.makedirs(os.path.join(OUTPUT_ROOT, cls), exist_ok=True)\n",
    "\n",
    "# standard pre-trained ResNet18 as the victim model\n",
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81ca9659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T15:05:42.001905Z",
     "iopub.status.busy": "2025-12-18T15:05:42.001609Z",
     "iopub.status.idle": "2025-12-18T15:06:13.731541Z",
     "shell.execute_reply": "2025-12-18T15:06:13.730983Z",
     "shell.execute_reply.started": "2025-12-18T15:05:42.001885Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=INPUT_ROOT, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    input_shape=(3, 224, 224),\n",
    "    nb_classes=1000, \n",
    "    clip_values=(0, 1),\n",
    "    device_type='gpu',\n",
    "    preprocessing=(np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be7677d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T15:06:19.335055Z",
     "iopub.status.busy": "2025-12-18T15:06:19.334774Z",
     "iopub.status.idle": "2025-12-18T15:29:59.761914Z",
     "shell.execute_reply": "2025-12-18T15:29:59.761147Z",
     "shell.execute_reply.started": "2025-12-18T15:06:19.335036Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting generation on 32500 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508/508 [23:40<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "attack = ProjectedGradientDescent(\n",
    "    estimator=classifier,\n",
    "    eps=EPSILON,\n",
    "    eps_step=2/255,\n",
    "    max_iter=10, \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"Starting generation on {len(dataset)} images...\")\n",
    "total_generated = 0\n",
    "\n",
    "for images, labels in tqdm(dataloader):\n",
    "    x_batch = images.cpu().numpy()\n",
    "    x_adv = attack.generate(x=x_batch)\n",
    "    \n",
    "    for i in range(len(x_adv)):\n",
    "        label_idx = labels[i].item()\n",
    "        class_name = classes[label_idx]\n",
    "        \n",
    "        img_arr = (x_adv[i] * 255).astype(np.uint8)\n",
    "        img_arr = np.transpose(img_arr, (1, 2, 0))\n",
    "        img_pil = Image.fromarray(img_arr)\n",
    "        \n",
    "        save_path = os.path.join(OUTPUT_ROOT, class_name, f\"adv_{total_generated}.png\")\n",
    "        img_pil.save(save_path)\n",
    "        total_generated += 1\n",
    "\n",
    "print(\"Generation Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcdc723f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T15:29:59.763466Z",
     "iopub.status.busy": "2025-12-18T15:29:59.763237Z",
     "iopub.status.idle": "2025-12-18T15:31:47.101591Z",
     "shell.execute_reply": "2025-12-18T15:31:47.100858Z",
     "shell.execute_reply.started": "2025-12-18T15:29:59.763445Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping dataset...\n",
      "Done! Download 'imagenet100_adversarial.zip' from Output.\n"
     ]
    }
   ],
   "source": [
    "print(\"Zipping dataset...\")\n",
    "shutil.make_archive('imagenet100_adversarial', 'zip', '/kaggle/working/imagenet100_adversarial')\n",
    "print(\"Done! Download 'imagenet100_adversarial.zip' from Output.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1500837,
     "sourceId": 2491748,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31240,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
