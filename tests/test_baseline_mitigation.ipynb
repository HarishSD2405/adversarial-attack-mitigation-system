{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09fabd09",
   "metadata": {},
   "source": [
    "# *Baseline* and *Mitigation* Models - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049090d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install adversarial-robustness-toolbox torch matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d391194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af079bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model architectures\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64,3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim = 1)\n",
    "        return output\n",
    "    \n",
    "# defining ResNet component adapted for MNIST 1 * 28 * 28\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride = 1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size = 1, stride = stride, bias = False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "# defining model architectures\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes = 10): # specifically for MNIST\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # 1 input channel for MNIST\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride = 1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride = 2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride = 2)\n",
    "        \n",
    "        # final linear layer adapted for 28 * 28 images after pooling\n",
    "        self.linear = nn.Linear(512 * block.expansion * 4 * 4, num_classes) \n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        layers.append(block(self.in_planes, planes, stride))\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(block(self.in_planes, planes, stride = 1))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        # average pooling for 28 * 28 input results in 3 * 3 feature map before flatten\n",
    "        out = F.avg_pool2d(out, 1) \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return F.log_softmax(out, dim = 1)\n",
    "        \n",
    "def ResNet18(num_classes = 10):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7880141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# checking for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "231f82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATHS = {\n",
    "    \"baseline_cnn\": \"../models/baseline_model_cnn.pth\",\n",
    "    \"mitigation_cnn\": \"../models/mitigation_model_cnn.pth\",\n",
    "    \"detection_cnn\": \"../models/detection_model_cnn.pth\",\n",
    "    \"baseline_resnet\": \"../models/baseline_model_resnet.pth\",\n",
    "    \"mitigation_resnet\": \"../models/mitigation_model_resnet.pth\",\n",
    "    \"detection_resnet\": \"../models/detection_model_resnet.pth\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc5c4b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [01:19<00:00, 124kB/s] \n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 77.0kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:04<00:00, 362kB/s] \n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.31MB/s]\n"
     ]
    }
   ],
   "source": [
    "# preparing the test data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_dataset = datasets.MNIST(root = './data', train = False, download = True, transform = transform)\n",
    "test_loader_clean = DataLoader(test_dataset, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a51a7867",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_for_art = SimpleCNN(num_classes = 10).to(device)\n",
    "try:\n",
    "    baseline_model_for_art.load_state_dict(torch.load(MODEL_PATHS[\"baseline_cnn\"], map_location = device))\n",
    "    baseline_model_for_art.eval()\n",
    "except:\n",
    "    print(\"Warning: Could not load CNN baseline model; initializing without saved weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e841dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Adversarial dataset with PGD Epsilon = 0.15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542ea143e6d743718034bdb15f276189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loki/miniconda3/envs/master-env/lib/python3.10/site-packages/torch/nn/functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial dataset saved to adv_test_dataset_pgd015.npy\n",
      "Adversarial test loader created\n"
     ]
    }
   ],
   "source": [
    "# generating an adversial attack\n",
    "\n",
    "ADVERSARIAL_DATASET_FILE = \"adv_test_dataset_pgd015.npy\"\n",
    "\n",
    "baseline_classifier_art = PyTorchClassifier(\n",
    "    model = baseline_model_for_art,\n",
    "    loss = nn.CrossEntropyLoss(),\n",
    "    input_shape = (1, 28, 28),\n",
    "    nb_classes = 10,\n",
    "    device_type = device\n",
    ")\n",
    "\n",
    "if os.path.exists(ADVERSARIAL_DATASET_FILE):\n",
    "    print(f\"Loading existing adversarial dataset from {ADVERSARIAL_DATASET_FILE}...\")\n",
    "    x_test_adv_np = np.load(ADVERSARIAL_DATASET_FILE)\n",
    "else:\n",
    "    print(f\"Creating Adversarial dataset with PGD Epsilon = 0.15\")\n",
    "    pgd_attack = ProjectedGradientDescent(baseline_classifier_art, eps = 0.15, eps_step = 0.01, max_iter = 40)\n",
    "\n",
    "    x_test_np = test_dataset.data.numpy().reshape(-1, 1, 28, 28).astype(np.float32) / 255.0\n",
    "    y_test_np = test_dataset.targets.numpy()\n",
    "\n",
    "    x_test_adv_np = pgd_attack.generate(x = x_test_np, y = y_test_np)\n",
    "    np.save(ADVERSARIAL_DATASET_FILE, x_test_adv_np)\n",
    "    print(f\"Adversarial dataset saved to {ADVERSARIAL_DATASET_FILE}\")\n",
    "\n",
    "y_test_np = test_dataset.targets.numpy()\n",
    "x_test_adv_tensor = torch.from_numpy(x_test_adv_np).to(device)\n",
    "adv_test_dataset = TensorDataset(x_test_adv_tensor, torch.from_numpy(y_test_np).long().to(device))\n",
    "adv_test_loader = DataLoader(adv_test_dataset, batch_size = 128, shuffle = False)\n",
    "print(\"Adversarial test loader created\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd5c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function\n",
    "def eval_model(model, loader, description, is_detection = False):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim = 1, keepdim = True)\n",
    "            if is_detection:\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            else:\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += data.size(0)\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print(f\"{description} Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0645b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model initialization and loading\n",
    "\n",
    "def load_model(architecture, num_classes, path):\n",
    "    model = architecture(num_classes).to(device)\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(path, map_location = device))\n",
    "        print(f\"Loaded {architecture.__name__} from {path}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not load {architecture.__name__} from {path}, skipping; error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35132750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SimpleCNN from ../models/baseline_model_cnn.pth\n",
      "Loaded SimpleCNN from ../models/mitigation_model_cnn.pth\n",
      "Loaded ResNet18 from ../models/baseline_model_resnet.pth\n",
      "Loaded ResNet18 from ../models/mitigation_model_resnet.pth\n"
     ]
    }
   ],
   "source": [
    "baseline_model_cnn = load_model(SimpleCNN, 10, MODEL_PATHS[\"baseline_cnn\"])\n",
    "mitigation_model_cnn = load_model(SimpleCNN, 10, MODEL_PATHS[\"mitigation_cnn\"])\n",
    "\n",
    "baseline_model_resnet = load_model(ResNet18, 10, MODEL_PATHS[\"baseline_resnet\"])\n",
    "mitigation_model_resnet = load_model(ResNet18, 10, MODEL_PATHS[\"mitigation_resnet\"])\n",
    "\n",
    "# detection_model_cnn = load_model(SimpleCNN, 2, MODEL_PATHS['detection_cnn'])\n",
    "# detection_model_resnet = load_model(ResNet18, 2, MODEL_PATHS['detection_resnet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f213a845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfomance Evaluation\n",
      "Baseline CNN (Clean Data) Accuracy: 99.02%\n",
      "Baseline CNN (Adversarial Data) Accuracy: 2.05%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m eval_model(baseline_model_cnn, test_loader_clean, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline CNN (Clean Data)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m eval_model(baseline_model_cnn, adv_test_loader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline CNN (Adversarial Data)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmitigation_model_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMitigation CNN (Clean Data)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m eval_model(mitigation_model_cnn, adv_test_loader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMitigation CNN (Adversarial Data)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(model, loader, description, is_detection)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m      7\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, keepdim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_detection:\n",
      "File \u001b[0;32m~/miniconda3/envs/master-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/master-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mSimpleCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m---> 16\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmax_pool2d(x, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/master-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/master-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/master-env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/master-env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# performance evaluation\n",
    "\n",
    "print(\"Perfomance Evaluation\")\n",
    "\n",
    "if baseline_model_cnn and mitigation_model_cnn:\n",
    "    eval_model(baseline_model_cnn, test_loader_clean, \"Baseline CNN (Clean Data)\")\n",
    "    eval_model(baseline_model_cnn, adv_test_loader, \"Baseline CNN (Adversarial Data)\")\n",
    "    \n",
    "    eval_model(mitigation_model_cnn, test_loader_clean, \"Mitigation CNN (Clean Data)\")\n",
    "    eval_model(mitigation_model_cnn, adv_test_loader, \"Mitigation CNN (Adversarial Data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a453fe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline ResNet (Clean Data) Accuracy: 98.89%\n",
      "Baseline ResNet (Adversarial Data) Accuracy: 9.74%\n",
      "Mitigation ResNet (Clean Data) Accuracy: 11.35%\n",
      "Mitigation ResNet (Adversarial Data) Accuracy: 11.35%\n"
     ]
    }
   ],
   "source": [
    "if baseline_model_resnet and mitigation_model_resnet:\n",
    "    eval_model(baseline_model_resnet, test_loader_clean, \"Baseline ResNet (Clean Data)\")\n",
    "    eval_model(baseline_model_resnet, adv_test_loader, \"Baseline ResNet (Adversarial Data)\")\n",
    "    \n",
    "    eval_model(mitigation_model_resnet, test_loader_clean, \"Mitigation ResNet (Clean Data)\")\n",
    "    eval_model(mitigation_model_resnet, adv_test_loader, \"Mitigation ResNet (Adversarial Data)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
