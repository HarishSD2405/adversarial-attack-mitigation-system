{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09fabd09",
   "metadata": {},
   "source": [
    "# *Baseline* and *Mitigation* Models - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049090d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install adversarial-robustness-toolbox torch matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d391194f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harishsd/adversarial-attack-mitigation-system/project-env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af079bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model architectures\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64,3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim = 1)\n",
    "        return output\n",
    "    \n",
    "# defining ResNet component adapted for MNIST 1 * 28 * 28\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride = 1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size = 1, stride = stride, bias = False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "# defining model architectures\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes = 10): # specifically for MNIST\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # 1 input channel for MNIST\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride = 1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride = 2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride = 2)\n",
    "        \n",
    "        # final linear layer adapted for 28 * 28 images after pooling\n",
    "        self.linear = nn.Linear(512 * block.expansion * 4 * 4, num_classes) \n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        layers.append(block(self.in_planes, planes, stride))\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(block(self.in_planes, planes, stride = 1))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        # average pooling for 28 * 28 input results in 3 * 3 feature map before flatten\n",
    "        out = F.avg_pool2d(out, 1) \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return F.log_softmax(out, dim = 1)\n",
    "        \n",
    "def ResNet18(num_classes = 10):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7880141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# checking for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "231f82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATHS = {\n",
    "    \"baseline_cnn\": \"../models/baseline_model_cnn.pth\",\n",
    "    \"mitigation_cnn\": \"../models/mitigation_model_cnn.pth\",\n",
    "    \"detection_cnn\": \"../models/detection_model_cnn.pth\",\n",
    "    \"baseline_resnet\": \"../models/baseline_model_resnet.pth\",\n",
    "    \"mitigation_resnet\": \"../models/mitigation_model_resnet_1.pth\",\n",
    "    \"detection_resnet\": \"../models/detection_model_resnet.pth\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc5c4b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the test data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_dataset = datasets.MNIST(root = './data', train = False, download = True, transform = transform)\n",
    "test_loader_clean = DataLoader(test_dataset, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a51a7867",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_for_art = SimpleCNN(num_classes = 10).to(device)\n",
    "try:\n",
    "    baseline_model_for_art.load_state_dict(torch.load(MODEL_PATHS[\"baseline_cnn\"], map_location = device))\n",
    "    baseline_model_for_art.eval()\n",
    "except:\n",
    "    print(\"Warning: Could not load CNN baseline model; initializing without saved weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing adversarial dataset from adv_test_dataset_pgd015.npy...\n",
      "Adversarial test loader created\n"
     ]
    }
   ],
   "source": [
    "# generating an adversial attack\n",
    "\n",
    "ADVERSARIAL_DATASET_FILE = \"adv_test_dataset_pgd015.npy\"\n",
    "\n",
    "baseline_classifier_art = PyTorchClassifier(\n",
    "    model = baseline_model_for_art,\n",
    "    loss = nn.CrossEntropyLoss(),\n",
    "    input_shape = (1, 28, 28),\n",
    "    nb_classes = 10,\n",
    "    device_type = device\n",
    ")\n",
    "\n",
    "if os.path.exists(ADVERSARIAL_DATASET_FILE):\n",
    "    print(f\"Loading existing adversariahhhl dataset from {ADVERSARIAL_DATASET_FILE}...\")\n",
    "    x_test_adv_np = np.load(ADVERSARIAL_DATASET_FILE)\n",
    "else:\n",
    "    print(f\"Creating Adversarial dataset with PGD Epsilon = 0.15\")\n",
    "    pgd_attack = ProjectedGradientDescent(baseline_classifier_art, eps = 0.15, eps_step = 0.01, max_iter = 40)\n",
    "\n",
    "    x_test_np = test_dataset.data.numpy().reshape(-1, 1, 28, 28).astype(np.float32) / 255.0\n",
    "    y_test_np = test_dataset.targets.numpy()\n",
    "\n",
    "    x_test_adv_np = pgd_attack.generate(x = x_test_np, y = y_test_np)\n",
    "    np.save(ADVERSARIAL_DATASET_FILE, x_test_adv_np)\n",
    "    print(f\"Adversarial dataset saved to {ADVERSARIAL_DATASET_FILE}\")\n",
    "\n",
    "y_test_np = test_dataset.targets.numpy()\n",
    "x_test_adv_tensor = torch.from_numpy(x_test_adv_np).to(device)\n",
    "adv_test_dataset = TensorDataset(x_test_adv_tensor, torch.from_numpy(y_test_np).long().to(device))\n",
    "adv_test_loader = DataLoader(adv_test_dataset, batch_size = 128, shuffle = False)\n",
    "print(\"Adversarial test loader created\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd5c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function\n",
    "def eval_model(model, loader, description, is_detection = False):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim = 1, keepdim = True)\n",
    "            if is_detection:\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            else:\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += data.size(0)\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print(f\"{description} Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0645b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model initialization and loading\n",
    "\n",
    "def load_model(architecture, num_classes, path):\n",
    "    model = architecture(num_classes).to(device)\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(path, map_location = device))\n",
    "        print(f\"Loaded {architecture.__name__} from {path}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not load {architecture.__name__} from {path}, skipping; error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35132750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SimpleCNN from ../models/baseline_model_cnn.pth\n",
      "Loaded SimpleCNN from ../models/mitigation_model_cnn.pth\n",
      "Loaded ResNet18 from ../models/baseline_model_resnet.pth\n",
      "Loaded ResNet18 from ../models/mitigation_model_resnet_1.pth\n"
     ]
    }
   ],
   "source": [
    "baseline_model_cnn = load_model(SimpleCNN, 10, MODEL_PATHS[\"baseline_cnn\"])\n",
    "mitigation_model_cnn = load_model(SimpleCNN, 10, MODEL_PATHS[\"mitigation_cnn\"])\n",
    "\n",
    "baseline_model_resnet = load_model(ResNet18, 10, MODEL_PATHS[\"baseline_resnet\"])\n",
    "mitigation_model_resnet = load_model(ResNet18, 10, MODEL_PATHS[\"mitigation_resnet\"])\n",
    "\n",
    "# detection_model_cnn = load_model(SimpleCNN, 2, MODEL_PATHS['detection_cnn'])\n",
    "# detection_model_resnet = load_model(ResNet18, 2, MODEL_PATHS['detection_resnet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f213a845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfomance Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harishsd/adversarial-attack-mitigation-system/project-env/lib/python3.13/site-packages/torch/nn/functional.py:1535: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline CNN (Clean Data) Accuracy: 99.02%\n",
      "Baseline CNN (Adversarial Data) Accuracy: 2.05%\n",
      "Mitigation CNN (Clean Data) Accuracy: 98.63%\n",
      "Mitigation CNN (Adversarial Data) Accuracy: 72.03%\n"
     ]
    }
   ],
   "source": [
    "# performance evaluation\n",
    "\n",
    "print(\"Perfomance Evaluation\")\n",
    "\n",
    "if baseline_model_cnn and mitigation_model_cnn:\n",
    "    eval_model(baseline_model_cnn, test_loader_clean, \"Baseline CNN (Clean Data)\")\n",
    "    eval_model(baseline_model_cnn, adv_test_loader, \"Baseline CNN (Adversarial Data)\")\n",
    "    \n",
    "    eval_model(mitigation_model_cnn, test_loader_clean, \"Mitigation CNN (Clean Data)\")\n",
    "    eval_model(mitigation_model_cnn, adv_test_loader, \"Mitigation CNN (Adversarial Data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a453fe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline ResNet (Clean Data) Accuracy: 98.89%\n",
      "Baseline ResNet (Adversarial Data) Accuracy: 9.74%\n",
      "Mitigation ResNet (Clean Data) Accuracy: 99.33%\n",
      "Mitigation ResNet (Adversarial Data) Accuracy: 72.41%\n"
     ]
    }
   ],
   "source": [
    "if baseline_model_resnet and mitigation_model_resnet:\n",
    "    eval_model(baseline_model_resnet, test_loader_clean, \"Baseline ResNet (Clean Data)\")\n",
    "    eval_model(baseline_model_resnet, adv_test_loader, \"Baseline ResNet (Adversarial Data)\")\n",
    "    \n",
    "    eval_model(mitigation_model_resnet, test_loader_clean, \"Mitigation ResNet (Clean Data)\")\n",
    "    eval_model(mitigation_model_resnet, adv_test_loader, \"Mitigation ResNet (Adversarial Data)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
